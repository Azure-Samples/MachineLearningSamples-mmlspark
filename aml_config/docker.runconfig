<<<<<<< HEAD
ArgumentVector:
  - "$file"
Target: "docker"
EnvironmentVariables:
  "EXAMPLE_ENV_VAR": "Example Value"
Framework: "PySpark"
CondaDependenciesFile: "aml_config/conda_dependencies.yml"
SparkDependenciesFile: "aml_config/spark_dependencies.yml"
PrepareEnvironment: true
=======
# The program name and arguments to run when they aren't specified through
# other means. The $file token is replaced with the currently selected file
# by the Workbench application.
ArgumentVector:
  - "$file"

# The name of the compute target to use for this run.
Target: "docker"

# Environment variables set for the run.
EnvironmentVariables:
  "EXAMPLE_ENV_VAR": "Example Value"

# Framework to execute inside. Allowed values are "Python" and "PySpark".
Framework: "PySpark"

# Path to the Conda dependencies file to use for this run. If a project
# contains multiple programs with different sets of dependencies, it may be
# convenient to manage those environments with separate files.
CondaDependenciesFile: "aml_config/conda_dependencies.yml"

# Path to the Spark dependencies file to use for this run. If a project
# contains multiple programs with different sets of dependencies, it may be
# convenient to manage those environments with separate files.
SparkDependenciesFile: "aml_config/spark_dependencies.yml"

# Automatically prepare the run environment as part of the run itself.
# Manual preparation of a compute target can be perfomed with:
# az ml experiment prepare --run-configuration <run configuration name>
PrepareEnvironment: true

# Enable history tracking -- this allows status, logs, metrics, and outputs
# to be collected by Azure ML Workbench and uploaded to the cloud project.
>>>>>>> 1aff16e292d0a2389e4877ec7c1a3b101fbbc25a
TrackedRun: true
